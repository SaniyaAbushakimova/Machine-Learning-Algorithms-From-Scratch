{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Date: 10/30/2024"
      ],
      "metadata": {
        "id": "6TbkoWoJt0Cm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKpnzLwg9pig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b0cf85-eea1-419f-d90d-2e1d4f559eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect to drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "056SvG2yia55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Gaussian Mixtures"
      ],
      "metadata": {
        "id": "TZK4ZF0ptsPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_mahalanobis_dist(data, sigma, mu):\n",
        "\n",
        "  U, D, _ = np.linalg.svd(sigma)\n",
        "  D_tilde = np.diag(1/np.sqrt(D))\n",
        "\n",
        "  data_tilde = (D_tilde @ U.T @ data.T).T\n",
        "  data_tilde_reshaped = data_tilde[:, np.newaxis, :]\n",
        "\n",
        "  mu_tilde = (D_tilde @ U.T @ mu.T).T\n",
        "  mu_tilde_reshaped = mu_tilde[np.newaxis, :, :]\n",
        "\n",
        "  mahalanobis_dist = np.sum((data_tilde_reshaped - mu_tilde_reshaped)**2, axis=2)\n",
        "\n",
        "  return mahalanobis_dist"
      ],
      "metadata": {
        "id": "KB8rVuSFGmVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate responsibility matrix r_nk\n",
        "def Estep(data, sigma, mu, p_k):\n",
        "\n",
        "  n, p = data.shape\n",
        "  G = mu.shape[0]\n",
        "\n",
        "  # Compute Mahalanobis Dist: (x_i - mu_k)^T @ sigma^(-1) @ (x_i-mu_k)\n",
        "  mahalanobis_dist = calc_mahalanobis_dist(data, sigma, mu)\n",
        "\n",
        "  # Compute responsibility matrix r_nk\n",
        "  exp_term = np.exp(-0.5 * mahalanobis_dist)\n",
        "  const_term = 1/np.sqrt(((2 * np.pi)**p) * np.linalg.det(sigma))\n",
        "\n",
        "  weighted_pdfs = p_k * const_term * exp_term\n",
        "  denominator = np.sum(weighted_pdfs, axis=1, keepdims=True)\n",
        "\n",
        "  r_nk = weighted_pdfs/denominator\n",
        "\n",
        "  return r_nk"
      ],
      "metadata": {
        "id": "gICzA-47pd7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update parameters p_k, mu, sigma\n",
        "def Mstep(data, r_nk):\n",
        "\n",
        "  n, p = data.shape\n",
        "  G = r_nk.shape[1]\n",
        "\n",
        "  # Update mixing probability\n",
        "  p_k = np.sum(r_nk, axis=0)/n\n",
        "\n",
        "  # Update mean matrix\n",
        "  mu = (r_nk.T @ data) / (np.sum(r_nk, axis=0)[:, np.newaxis])\n",
        "\n",
        "  # Update covariance matrix\n",
        "  sigma = np.zeros((p, p))\n",
        "\n",
        "  for k in range(G):\n",
        "    data_centered = data - mu[k]\n",
        "    sigma = sigma + (r_nk[:, k][:, np.newaxis] * data_centered).T @ data_centered\n",
        "\n",
        "  sigma = sigma/np.sum(r_nk)\n",
        "\n",
        "  return p_k, mu, sigma"
      ],
      "metadata": {
        "id": "OcYU6eNMvdYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate log-likelihood\n",
        "def loglik(data, sigma, mu, p_k):\n",
        "\n",
        "  n, p = data.shape\n",
        "  G = mu.shape[0]\n",
        "\n",
        "  # 1. Compute Mahalanobis Dist: (x_i - mu_k)^T @ sigma^(-1) @ (x_i-mu_k)\n",
        "  mahalanobis_dist = calc_mahalanobis_dist(data, sigma, mu)\n",
        "\n",
        "  # 2. Calculate log-likelihood\n",
        "  exp_term = np.exp(-0.5 * mahalanobis_dist)\n",
        "  const_term = 1/np.sqrt(((2 * np.pi)**p) * np.linalg.det(sigma))\n",
        "\n",
        "  weighted_pdfs = p_k * const_term * exp_term\n",
        "  total_pdfs = np.sum(weighted_pdfs, axis=1)\n",
        "\n",
        "  loglik_val = np.sum(np.log(total_pdfs))\n",
        "\n",
        "  return loglik_val"
      ],
      "metadata": {
        "id": "ta2X95PLG3pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def myEM(data, G, sigma, mu, p_k, itmax):\n",
        "\n",
        "  for i in range(itmax):\n",
        "    # E-step: calculate responsibilities\n",
        "    r_nk = Estep(data, sigma, mu, p_k)\n",
        "\n",
        "    # M-step: update parameters based on responsibilities\n",
        "    p_k, mu, sigma = Mstep(data, r_nk)\n",
        "\n",
        "  # Compute the final log-likelihood with updated parameters\n",
        "  loglik_val = loglik(data, sigma, mu, p_k)\n",
        "\n",
        "  return p_k, mu.T, sigma, loglik_val"
      ],
      "metadata": {
        "id": "niWay2olMJaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "J9LYcowNJW6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"datasets/faithful.dat\", delim_whitespace=True)\n",
        "data = df.to_numpy()"
      ],
      "metadata": {
        "id": "yJFSN7p5JYlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFrtxi8RPGNc",
        "outputId": "526509ea-ed1b-499c-a522-eef51be07b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(272, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFBrcbwmPrke",
        "outputId": "536ae45a-bbcb-4c19-e63a-28430c54c05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.6  , 79.   ],\n",
              "       [ 1.8  , 54.   ],\n",
              "       [ 3.333, 74.   ],\n",
              "       [ 2.283, 62.   ],\n",
              "       [ 4.533, 85.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 1: G=2"
      ],
      "metadata": {
        "id": "3tdVXEobV8sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = 2\n",
        "n = data.shape[0]\n",
        "itmax = 20\n",
        "\n",
        "# Initial mixing probabilities p_k\n",
        "p1 = 10/n\n",
        "p2 = 1 - p1\n",
        "p_k = np.array([p1, p2])\n",
        "\n",
        "# Initial mean matrix\n",
        "mu1 = np.mean(data[:10], axis=0)\n",
        "mu2 = np.mean(data[10:], axis=0)\n",
        "mu = np.array([mu1, mu2])\n",
        "\n",
        "# Initial covariance matrix\n",
        "centered_data1 = data[:10] - mu1\n",
        "centered_data2 = data[10:] - mu2\n",
        "\n",
        "sigma = ((centered_data1.T @ centered_data1) + (centered_data2.T @ centered_data2)) / n\n",
        "\n",
        "# EM-algorithm\n",
        "p_k, mu, sigma, loglik_val = myEM(data, G, sigma, mu, p_k, itmax)"
      ],
      "metadata": {
        "id": "ct6tdoaiPJOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RZUEr0rSzVr",
        "outputId": "1d00d710-ed85-4402-88ff-3e24577537c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.04297883, 0.95702117])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5uDqCLAS0xg",
        "outputId": "77d52ef4-75b0-495f-afb4-a8ae9b0d7e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.49564188,  3.48743016],\n",
              "       [76.79789154, 70.63205853]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kT4Kcf1S1iO",
        "outputId": "252adea6-de09-47ce-a37b-ec8c8fc50c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.29793612,  13.92433626],\n",
              "       [ 13.92433626, 182.58009247]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loglik_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwXgFsckS239",
        "outputId": "eabe03f6-61d0-4609-9d9e-b55b230348fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1289.56935494241"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 2: G=3"
      ],
      "metadata": {
        "id": "Jxz4f2tHXMb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = 3\n",
        "itmax = 20\n",
        "\n",
        "# Initial mixing probabilities p_k\n",
        "p1 = 10/n\n",
        "p2 = 20/n\n",
        "p3 = 1 - p1 - p2\n",
        "p_k = np.array([p1, p2, p3])\n",
        "\n",
        "# Initial mean matrix\n",
        "mu1 = np.mean(data[:10], axis=0)\n",
        "mu2 = np.mean(data[10:30], axis=0)\n",
        "mu3 = np.mean(data[30:], axis=0)\n",
        "mu = np.array([mu1, mu2, mu3])\n",
        "\n",
        "# Initial covariance matrix\n",
        "centered_data1 = data[:10] - mu1\n",
        "centered_data2 = data[10:30] - mu2\n",
        "centered_data3 = data[30:] - mu3\n",
        "\n",
        "cov1 = centered_data1.T @ centered_data1\n",
        "cov2 = centered_data2.T @ centered_data2\n",
        "cov3 = centered_data3.T @ centered_data3\n",
        "sigma = (cov1 + cov2 + cov3) / n\n",
        "\n",
        "# EM-algorithm\n",
        "p_k, mu, sigma, loglik_val = myEM(data, G, sigma, mu, p_k, itmax)"
      ],
      "metadata": {
        "id": "IDYqfecrXMIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M34DoANbXu4B",
        "outputId": "c1b64863-3dc4-4ec6-841d-88161717aeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.04363422, 0.07718656, 0.87917922])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umB4uVa3m7iS",
        "outputId": "e0844750-5153-4e54-a560-309b1afbb93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.51006918,  2.81616674,  3.54564083],\n",
              "       [77.10563811, 63.35752634, 71.25084801]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ixU-tHgXwhB",
        "outputId": "cdc84b21-9303-402e-ad3a-71f00e49b8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.26015772,  13.51153756],\n",
              "       [ 13.51153756, 177.96419105]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loglik_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjA_jg4sXxEB",
        "outputId": "d358b926-cf5a-4613-ac1d-c35faca8c2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1289.350958862738"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: HMM"
      ],
      "metadata": {
        "id": "ZwiWW31JtxYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baum-Welch Algorithm"
      ],
      "metadata": {
        "id": "3CEu7IDEVaaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def BW_Estep(X, mx, mz, w, A, B):\n",
        "  # Calculate forward prob, alpha_t\n",
        "  alpha_t = np.zeros((len(X), mz))\n",
        "  alpha_t[0] = w * B[:, (X[0] - 1)]\n",
        "\n",
        "  for t in range(1, len(X)):\n",
        "      alpha_t[t, :] = (alpha_t[t-1, :] @ A) * B[:, (X[t] - 1)]\n",
        "\n",
        "  # Calculate backward prob, beta_t1\n",
        "  beta_t1 = np.zeros((len(X), mz))\n",
        "  beta_t1[len(X) - 1] = np.ones(mz)\n",
        "\n",
        "  for t in range(len(X)-2, -1, -1):\n",
        "      beta_t1[t, :] = A @ (B[:, (X[t+1] - 1)] * beta_t1[t+1, :])\n",
        "\n",
        "  # Calculate myGamma\n",
        "  myGamma = np.zeros((len(X)-1, mz, mz))\n",
        "  for t in range(len(X)-1):\n",
        "    temp = np.outer(alpha_t[t], beta_t1[t+1])\n",
        "    temp = temp * A\n",
        "    myGamma[t] = temp * B[:, (X[t+1] - 1)]\n",
        "\n",
        "  return myGamma\n",
        "\n",
        "def BW_Mstep(X, mx, mz, A, B, myGamma):\n",
        "  # Update A matrix\n",
        "  numerator = np.sum(myGamma, axis=0)\n",
        "  A_update = numerator / np.sum(numerator, axis=1, keepdims=True)\n",
        "\n",
        "  # Calculate gamma_i matrix for B update\n",
        "  gamma_ti = np.zeros((len(X), mz))\n",
        "\n",
        "  for t in range(len(X)-1):\n",
        "     gamma_ti[t] = np.sum(myGamma[t], axis=1)\n",
        "\n",
        "  # Calculate last element of gamma_i seperately since it sums over first axis\n",
        "  gamma_ti[-1] = np.sum(myGamma[-1], axis=0)\n",
        "\n",
        "  # Update B matrix\n",
        "  B_update = np.zeros((mz, mx))\n",
        "  for i in range(mz):\n",
        "    for l in range(mx):\n",
        "      numerator = 0\n",
        "      for t in range(len(X)):\n",
        "        if X[t] == l+1:\n",
        "          numerator += gamma_ti[t, i]\n",
        "      B_update[i, l] = numerator / np.sum(gamma_ti[:, i])\n",
        "\n",
        "  return A_update, B_update\n",
        "\n",
        "def BW_onestep(X, mx, mz, w, A, B):\n",
        "  # E-Step\n",
        "  myGamma = BW_Estep(X, mx, mz, w, A, B)\n",
        "\n",
        "  # M-Step\n",
        "  A_update, B_update = BW_Mstep(X, mx, mz, A, B, myGamma)\n",
        "\n",
        "  return A_update, B_update\n",
        "\n",
        "# Run for 100 iterations\n",
        "def myBW(data, mx, mz, w, A, B):\n",
        "  for i in range(100):\n",
        "    A, B = BW_onestep(data, mx, mz, w, A, B)\n",
        "\n",
        "  return A, B"
      ],
      "metadata": {
        "id": "1obFOnbiVZf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Viterbi Algorithm"
      ],
      "metadata": {
        "id": "3k3UFb1KViWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to run calculations in log scale, so use sums of logs instead of log of product\n",
        "# When outputing sequence path make sure to calculate outputs correctly, e.g. +1 if needed\n",
        "# Function assumes we have already ran Baum-Welch to get MLE of A, B\n",
        "def myViterbi(X, mx, mz, w, A, B):\n",
        "  # Calculate delta_ti\n",
        "  delta_ti = np.zeros((len(X), mz))\n",
        "  #delta_ti[0] = np.log(w * B[:, (X[0] - 1)])\n",
        "  delta_ti[0] = np.log(w) + np.log(B[:, (X[0] - 1)])\n",
        "\n",
        "  for t in range(1, len(X)):\n",
        "    for i in range(mz):\n",
        "      max_prev = max(delta_ti[t-1, j] + np.log(A[j, i]) for j in range(mz))\n",
        "      # delta_ti[t, i] = np.log(np.exp(max_prev) * B[i, (X[t] - 1)])\n",
        "      delta_ti[t, i] = max_prev + np.log(B[i, (X[t] - 1)])\n",
        "\n",
        "  # Calculate Z* hat, which is the most likely single sequence backwards\n",
        "  Z_hat = np.zeros(len(X), dtype=int)\n",
        "  Z_hat[-1] = np.argmax(delta_ti[-1]) + 1\n",
        "  for t in range(len(X)-2, -1, -1):\n",
        "    Z_hat[t] = np.argmax(delta_ti[t] + np.log(A[:, (Z_hat[t+1] - 1)])) + 1\n",
        "\n",
        "  return Z_hat"
      ],
      "metadata": {
        "id": "m3bD7fZ6Vlax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "3EDoo3CKVl6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Testing with given intial values\n",
        "\n",
        "# Initalizing values & Loading Data\n",
        "w =  np.array([0.5, 0.5])\n",
        "A = np.array([[0.5, 0.5],\n",
        "              [0.5, 0.5]])\n",
        "B = np.array([[1/9, 3/9, 5/9],\n",
        "              [1/6, 2/6, 3/6]])\n",
        "mz = 2\n",
        "\n",
        "x = np.loadtxt(\"datasets/coding4_part2_data.txt\", dtype=int)\n",
        "mx = len(np.unique(x))\n",
        "\n",
        "# Testing Baum-Welch\n",
        "\n",
        "A, B = myBW(x, mx, mz, w, A, B)\n",
        "print(\"A: the 2-by-2 transition matrix \")\n",
        "print(A)\n",
        "print(\"B: the 2-by-3 emission matrix \")\n",
        "print(B)\n"
      ],
      "metadata": {
        "id": "DCvXcn-fVoDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7855896-918c-4ccf-f58e-728ccf47bdfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: the 2-by-2 transition matrix \n",
            "[[0.49793938 0.50206062]\n",
            " [0.44883431 0.55116569]]\n",
            "B: the 2-by-3 emission matrix \n",
            "[[0.22159897 0.20266127 0.57573976]\n",
            " [0.34175148 0.17866665 0.47958186]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the results of our Baum-Welch Algorithm matches the results given in the assignment description."
      ],
      "metadata": {
        "id": "ftYCiHJfYwOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Viterbi, make sure to run the BW algorithm first (i.e. the cell above) to avoid issues with results not matching up\n",
        "with open(\"datasets/Coding4_part2_Z.txt\", \"r\") as f:\n",
        "    file_content = f.read()\n",
        "viterbi_actual = np.array([int(x) for x in file_content.replace(\"\\n\", \" \").split()])\n",
        "\n",
        "\n",
        "viterbi_predicted = myViterbi(x, mx, mz, w, A, B)\n",
        "\n",
        "print(\"Number of mismatches:\")\n",
        "print(np.sum(viterbi_actual != viterbi_predicted))\n",
        "print(\"Predicted sequence:\")\n",
        "print(viterbi_predicted)\n",
        "print(\"Actual sequence:\")\n",
        "print(viterbi_actual)"
      ],
      "metadata": {
        "id": "U1kwfN4oRI2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d9ee93-0453-4759-b975-5d4fb53ecff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mismatches:\n",
            "0\n",
            "Predicted sequence:\n",
            "[1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 2 1 1\n",
            " 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 2 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1\n",
            " 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n",
            " 2 2 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 1 1 1 1 1\n",
            " 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1]\n",
            "Actual sequence:\n",
            "[1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 2 1 1\n",
            " 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 2 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1\n",
            " 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n",
            " 2 2 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 1 1 1 1 1\n",
            " 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the result from the viterbi algorithm also match the assignment description."
      ],
      "metadata": {
        "id": "x4X-elTId2py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Testing with B having all entries as 1/3\n",
        "w =  np.array([0.5, 0.5])\n",
        "A = np.array([[0.5, 0.5],\n",
        "              [0.5, 0.5]])\n",
        "mz = 2\n",
        "B = np.array([[1/3, 1/3, 1/3],\n",
        "              [1/3, 1/3, 1/3]])\n",
        "\n",
        "for i in range(20):\n",
        "  A, B = BW_onestep(x, mx, mz, w, A, B)\n",
        "print(\"A: the 2-by-2 transition matrix \")\n",
        "print(A)\n",
        "print(\"B: the 2-by-3 emission matrix \")\n",
        "print(B)"
      ],
      "metadata": {
        "id": "Ein8ZyAUWALV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c0f9a96-de54-4e63-fd5b-9e936c4579f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: the 2-by-2 transition matrix \n",
            "[[0.5 0.5]\n",
            " [0.5 0.5]]\n",
            "B: the 2-by-3 emission matrix \n",
            "[[0.285 0.19  0.525]\n",
            " [0.285 0.19  0.525]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we initialize B with all entries as $\\dfrac{1}{3}$ we see that, the matrix A remains the same as its initial representation and the matrix B has two identical rows. Making the latent states indistinguishable, makes it impossible for the Baum-Welch algorithm to differentiate between latent states. This is because when calculating the forward & backward probabilities and then the myGamma matrix, we just get a matrix that will end up scaling A or B by some amount. In this case, the A matrix was just scaled by 1 while the B matrix was scaled in a way the emission probabilities from both possible states of Z are identical. Then as we continue looping, the probabilities still remain in a way that makes it impossible to distinguish between latent states so then we continue to get updates that just scale the A & B matrices."
      ],
      "metadata": {
        "id": "WtzP76YRV8cI"
      }
    }
  ]
}