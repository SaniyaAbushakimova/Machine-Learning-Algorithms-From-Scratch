{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Zq0VwX_0ZG7o"},"outputs":[],"source":["# fill in the path in your Google Drive in the string below. Note: do not escape slashes or spaces\n","import os\n","datadir = \"path/\"\n","if not os.path.exists(datadir):\n","  !ln -s \"path/\" $datadir\n","os.chdir(datadir)\n","!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwTWWHmuZG7o"},"outputs":[],"source":["# downloading Fashion-MNIST\n","import os\n","os.chdir(os.path.join(datadir,\"fashion-mnist/\"))\n","!chmod +x ./get_data.sh\n","!./get_data.sh\n","os.chdir(datadir)"]},{"cell_type":"markdown","metadata":{"id":"hfatOGV-ZG7p"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7Jw0fSzZG7p"},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","from data_process import get_FASHION_data, get_RICE_data\n","from scipy.spatial import distance\n","from models import Perceptron, SVM, Softmax, Logistic\n","from kaggle_submission import output_submission_csv\n","%matplotlib inline\n","\n","# For auto-reloading external modules\n","# See http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"qz_unlIIZG7p"},"source":["# Loading Fashion-MNIST"]},{"cell_type":"markdown","metadata":{"id":"r2QPkTdKZG7q"},"source":["As part of the preprocessing pipeline, I defined the dataset splits. The combined training and validation set included 60,000 images, while the test set consisted of 10,000 images. These were then loaded and prepared for training and evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"faYTs3RrZG7q"},"outputs":[],"source":["# You can change these numbers for experimentation\n","# For submission we will use the default values\n","TRAIN_IMAGES = 50000\n","VAL_IMAGES = 10000\n","normalize = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWX4omAWZG7q"},"outputs":[],"source":["data = get_FASHION_data(TRAIN_IMAGES, VAL_IMAGES, normalize=normalize)\n","X_train_fashion, y_train_fashion = data['X_train'], data['y_train']\n","X_val_fashion, y_val_fashion = data['X_val'], data['y_val']\n","X_test_fashion, y_test_fashion = data['X_test'], data['y_test']\n","n_class_fashion = len(np.unique(y_test_fashion))\n","\n","# Standardizing the input features\n","mean_fmnist = np.mean(X_train_fashion, axis=0)\n","std_fmnist = np.std(X_train_fashion, axis=0)\n","\n","X_train_fashion = (X_train_fashion - mean_fmnist) / (std_fmnist + 1e-8)  # Avoid division by zero\n","X_val_fashion = (X_val_fashion - mean_fmnist) / (std_fmnist + 1e-8)\n","X_test_fashion = (X_test_fashion - mean_fmnist) / (std_fmnist + 1e-8)\n","\n","# Adding the bias term\n","X_train_fashion = np.concatenate((np.ones((X_train_fashion.shape[0], 1)), X_train_fashion), axis=1)\n","X_val_fashion = np.concatenate((np.ones((X_val_fashion.shape[0], 1)), X_val_fashion), axis=1)\n","X_test_fashion = np.concatenate((np.ones((X_test_fashion.shape[0], 1)), X_test_fashion), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"elapsed":114,"status":"ok","timestamp":1740100513670,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"9KAzOkuxLqfd","outputId":"3f49fed7-76ad-4e0f-cc9a-8dac02e511e4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>775</th>\n","      <th>776</th>\n","      <th>777</th>\n","      <th>778</th>\n","      <th>779</th>\n","      <th>780</th>\n","      <th>781</th>\n","      <th>782</th>\n","      <th>783</th>\n","      <th>784</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>-0.00892</td>\n","      <td>-0.022843</td>\n","      <td>-0.038668</td>\n","      <td>-0.042039</td>\n","      <td>-0.05897</td>\n","      <td>-0.071120</td>\n","      <td>-0.098286</td>\n","      <td>-0.156807</td>\n","      <td>-0.239129</td>\n","      <td>...</td>\n","      <td>-0.600456</td>\n","      <td>-0.474466</td>\n","      <td>-0.393991</td>\n","      <td>-0.404943</td>\n","      <td>-0.441078</td>\n","      <td>-0.396479</td>\n","      <td>-0.287818</td>\n","      <td>-0.156079</td>\n","      <td>-0.089607</td>\n","      <td>-0.033796</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>-0.00892</td>\n","      <td>-0.022843</td>\n","      <td>-0.038668</td>\n","      <td>-0.042039</td>\n","      <td>-0.05897</td>\n","      <td>0.102318</td>\n","      <td>-0.098286</td>\n","      <td>-0.156807</td>\n","      <td>-0.239129</td>\n","      <td>...</td>\n","      <td>1.471715</td>\n","      <td>1.860906</td>\n","      <td>2.706860</td>\n","      <td>1.332602</td>\n","      <td>-0.441078</td>\n","      <td>-0.396479</td>\n","      <td>-0.287818</td>\n","      <td>-0.156079</td>\n","      <td>-0.089607</td>\n","      <td>-0.033796</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>-0.00892</td>\n","      <td>-0.022843</td>\n","      <td>-0.038668</td>\n","      <td>-0.042039</td>\n","      <td>-0.05897</td>\n","      <td>-0.071120</td>\n","      <td>-0.098286</td>\n","      <td>-0.156807</td>\n","      <td>-0.239129</td>\n","      <td>...</td>\n","      <td>-0.600456</td>\n","      <td>-0.474466</td>\n","      <td>-0.370139</td>\n","      <td>-0.404943</td>\n","      <td>-0.441078</td>\n","      <td>-0.396479</td>\n","      <td>-0.287818</td>\n","      <td>-0.156079</td>\n","      <td>-0.089607</td>\n","      <td>-0.033796</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>-0.00892</td>\n","      <td>-0.022843</td>\n","      <td>-0.038668</td>\n","      <td>-0.042039</td>\n","      <td>-0.05897</td>\n","      <td>-0.071120</td>\n","      <td>-0.098286</td>\n","      <td>-0.156807</td>\n","      <td>1.140259</td>\n","      <td>...</td>\n","      <td>-0.600456</td>\n","      <td>-0.474466</td>\n","      <td>-0.393991</td>\n","      <td>-0.404943</td>\n","      <td>-0.441078</td>\n","      <td>-0.396479</td>\n","      <td>-0.287818</td>\n","      <td>-0.156079</td>\n","      <td>-0.089607</td>\n","      <td>-0.033796</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>-0.00892</td>\n","      <td>-0.022843</td>\n","      <td>-0.038668</td>\n","      <td>-0.042039</td>\n","      <td>-0.05897</td>\n","      <td>-0.071120</td>\n","      <td>-0.098286</td>\n","      <td>-0.156807</td>\n","      <td>-0.239129</td>\n","      <td>...</td>\n","      <td>-0.600456</td>\n","      <td>-0.474466</td>\n","      <td>-0.393991</td>\n","      <td>-0.404943</td>\n","      <td>-0.441078</td>\n","      <td>-0.396479</td>\n","      <td>-0.287818</td>\n","      <td>-0.156079</td>\n","      <td>-0.089607</td>\n","      <td>-0.033796</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 785 columns</p>\n","</div>"],"text/plain":["   0        1         2         3         4        5         6         7    \\\n","0  1.0 -0.00892 -0.022843 -0.038668 -0.042039 -0.05897 -0.071120 -0.098286   \n","1  1.0 -0.00892 -0.022843 -0.038668 -0.042039 -0.05897  0.102318 -0.098286   \n","2  1.0 -0.00892 -0.022843 -0.038668 -0.042039 -0.05897 -0.071120 -0.098286   \n","3  1.0 -0.00892 -0.022843 -0.038668 -0.042039 -0.05897 -0.071120 -0.098286   \n","4  1.0 -0.00892 -0.022843 -0.038668 -0.042039 -0.05897 -0.071120 -0.098286   \n","\n","        8         9    ...       775       776       777       778       779  \\\n","0 -0.156807 -0.239129  ... -0.600456 -0.474466 -0.393991 -0.404943 -0.441078   \n","1 -0.156807 -0.239129  ...  1.471715  1.860906  2.706860  1.332602 -0.441078   \n","2 -0.156807 -0.239129  ... -0.600456 -0.474466 -0.370139 -0.404943 -0.441078   \n","3 -0.156807  1.140259  ... -0.600456 -0.474466 -0.393991 -0.404943 -0.441078   \n","4 -0.156807 -0.239129  ... -0.600456 -0.474466 -0.393991 -0.404943 -0.441078   \n","\n","        780       781       782       783       784  \n","0 -0.396479 -0.287818 -0.156079 -0.089607 -0.033796  \n","1 -0.396479 -0.287818 -0.156079 -0.089607 -0.033796  \n","2 -0.396479 -0.287818 -0.156079 -0.089607 -0.033796  \n","3 -0.396479 -0.287818 -0.156079 -0.089607 -0.033796  \n","4 -0.396479 -0.287818 -0.156079 -0.089607 -0.033796  \n","\n","[5 rows x 785 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Checking bias term\n","X_train_fashion_df = pd.DataFrame(X_train_fashion)\n","X_train_fashion_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1740100514720,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"UfQ6EG4uL0Tv","outputId":"5ca00734-f56e-4417-f903-e7e85cc3ad6a"},"outputs":[{"data":{"text/plain":["(50000, 785)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["X_train_fashion.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1740100515294,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"4xnkHvaMYNkX","outputId":"8e4f3571-7036-476c-cec0-c19297cc82f5"},"outputs":[{"data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Check labels\n","np.unique(y_train_fashion)"]},{"cell_type":"markdown","metadata":{"id":"5-iPcUuBZG7r"},"source":["# Loading Rice"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":114,"status":"ok","timestamp":1740100516712,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"jyZKoVJGZG7r","outputId":"24b6fb3e-7aa6-426c-9886-ea9523fcb121"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of train samples:  10911\n","Number of val samples:  3637\n","Number of test samples:  3637\n"]}],"source":["# loads train / test / val splits of 80%, 20%, 20%\n","data = get_RICE_data()\n","X_train_RICE, y_train_RICE = data['X_train'], data['y_train']\n","X_val_RICE, y_val_RICE = data['X_val'], data['y_val']\n","X_test_RICE, y_test_RICE = data['X_test'], data['y_test']\n","n_class_RICE = len(np.unique(y_test_RICE))\n","\n","# Normalizing the input features\n","X_min = np.min(X_train_RICE, axis=0)\n","X_max = np.max(X_train_RICE, axis=0)\n","\n","X_train_RICE = (X_train_RICE - X_min) / (X_max - X_min + 1e-8)  # Avoid division by zero\n","X_val_RICE = (X_val_RICE - X_min) / (X_max - X_min + 1e-8)\n","X_test_RICE = (X_test_RICE - X_min) / (X_max - X_min + 1e-8)\n","\n","# Adding bias term\n","X_train_RICE = np.concatenate((np.ones((X_train_RICE.shape[0], 1)), X_train_RICE), axis=1)\n","X_val_RICE = np.concatenate((np.ones((X_val_RICE.shape[0], 1)), X_val_RICE), axis=1)\n","X_test_RICE = np.concatenate((np.ones((X_test_RICE.shape[0], 1)), X_test_RICE), axis=1)\n","\n","print(\"Number of train samples: \", X_train_RICE.shape[0])\n","print(\"Number of val samples: \", X_val_RICE.shape[0])\n","print(\"Number of test samples: \", X_test_RICE.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":84,"status":"ok","timestamp":1740100517897,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"WI54TQN3L6TB","outputId":"0204fe90-af25-46b9-afb7-b3db48ad3a3b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>0.356436</td>\n","      <td>0.407258</td>\n","      <td>0.687030</td>\n","      <td>0.306649</td>\n","      <td>0.920318</td>\n","      <td>0.397153</td>\n","      <td>0.491233</td>\n","      <td>0.392875</td>\n","      <td>0.427973</td>\n","      <td>0.606272</td>\n","      <td>0.653406</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>0.858306</td>\n","      <td>0.643730</td>\n","      <td>0.672747</td>\n","      <td>0.641852</td>\n","      <td>0.757312</td>\n","      <td>0.622030</td>\n","      <td>0.712551</td>\n","      <td>0.469772</td>\n","      <td>0.487210</td>\n","      <td>0.794097</td>\n","      <td>0.353259</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.767272</td>\n","      <td>0.775234</td>\n","      <td>0.742581</td>\n","      <td>0.748991</td>\n","      <td>0.737778</td>\n","      <td>0.765718</td>\n","      <td>0.823969</td>\n","      <td>0.402064</td>\n","      <td>0.567474</td>\n","      <td>0.780315</td>\n","      <td>0.331277</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.122002</td>\n","      <td>0.296436</td>\n","      <td>0.516953</td>\n","      <td>0.266393</td>\n","      <td>0.878944</td>\n","      <td>0.293812</td>\n","      <td>0.375204</td>\n","      <td>0.336607</td>\n","      <td>0.331205</td>\n","      <td>0.635043</td>\n","      <td>0.547932</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.699230</td>\n","      <td>0.929240</td>\n","      <td>0.821544</td>\n","      <td>0.861049</td>\n","      <td>0.722044</td>\n","      <td>0.911510</td>\n","      <td>0.946311</td>\n","      <td>0.595672</td>\n","      <td>0.636390</td>\n","      <td>0.803058</td>\n","      <td>0.314802</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    0         1         2         3         4         5         6         7   \\\n","0  1.0  0.356436  0.407258  0.687030  0.306649  0.920318  0.397153  0.491233   \n","1  1.0  0.858306  0.643730  0.672747  0.641852  0.757312  0.622030  0.712551   \n","2  1.0  0.767272  0.775234  0.742581  0.748991  0.737778  0.765718  0.823969   \n","3  1.0  0.122002  0.296436  0.516953  0.266393  0.878944  0.293812  0.375204   \n","4  1.0  0.699230  0.929240  0.821544  0.861049  0.722044  0.911510  0.946311   \n","\n","         8         9         10        11  \n","0  0.392875  0.427973  0.606272  0.653406  \n","1  0.469772  0.487210  0.794097  0.353259  \n","2  0.402064  0.567474  0.780315  0.331277  \n","3  0.336607  0.331205  0.635043  0.547932  \n","4  0.595672  0.636390  0.803058  0.314802  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Checking bias term\n","X_train_RICE_df = pd.DataFrame(X_train_RICE)\n","X_train_RICE_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1740100519279,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"rQWyzYrNMU96","outputId":"3c671a93-b9f4-45a8-db0b-4a9c768c2401"},"outputs":[{"data":{"text/plain":["(10911, 12)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["X_train_RICE.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1740100520170,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"VuUyVyu3U6zj","outputId":"82537a4e-1b31-480f-f203-43e61e59330f"},"outputs":[{"data":{"text/plain":["array([-1,  1])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Check labels\n","np.unique(y_test_RICE)"]},{"cell_type":"markdown","metadata":{"id":"vFqqV2ypZG7r"},"source":["### Get Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KEE6uv25ZG7r"},"outputs":[],"source":["def get_acc(pred, y_test):\n","    return np.sum(y_test == pred) / len(y_test) * 100"]},{"cell_type":"markdown","metadata":{"id":"1eiFeiAUZG7r"},"source":["# Perceptron"]},{"cell_type":"markdown","metadata":{"id":"FsNUhSKyZG7r"},"source":["In this project, I implemented a Perceptron classifier and explored the effects of two key hyperparameters: learning rate and number of training epochs. Through experimentation and tuning, I was able to observe how these parameters influenced model performance and convergence behavior.\n","\n","The implementation was developed in **models/perceptron.py**.\n","\n","### Hyperparameter 1: Learning rate\n","The learning rate determines the magnitude of weight updates during training. I began with a default value of 0.5 and experimented with a range of values from 0.0005 to 5.0 to study their impact on accuracy and training dynamics.\n","\n","Here’s what I found:\n","* High learning rates (e.g., 0.5 or above) sometimes caused the model to diverge or exhibit unstable loss patterns. Reducing the rate by a factor of 10 (e.g., from 0.5 to 0.05) helped stabilize training.\n","* Low learning rates led to very slow convergence. In such cases, increasing the rate (e.g., from 0.005 to 0.05) improved training speed.\n","* I also experimented with learning rate decay by reducing the learning rate gradually over epochs (e.g., multiplying by 0.95 after each epoch), which helped fine-tune the model as training progressed.\n","* To visualize the effect of different learning rates, I plotted training and validation accuracy across epochs.\n","\n","### Hyperparameter 2: Number of Epochs\n","An epoch refers to one full pass through the training dataset, where the model makes predictions and updates weights according to the Perceptron update rule.\n","\n","To evaluate convergence, I:\n","* Monitored accuracy trends on both the training and validation sets.\n","* Increased the number of epochs when I noticed that accuracy plateaued early or the model failed to converge.\n","* Compared performance across different values of epochs to find an optimal balance between training time and accuracy.\n","\n","These hyperparameter experiments provided valuable insights into the sensitivity of the Perceptron model and helped me better understand how to tune simple neural classifiers for improved performance."]},{"cell_type":"markdown","metadata":{"id":"_n1mxeX-ZG7r"},"source":["## Train Perceptron on Fashion-MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16570,"status":"ok","timestamp":1739909880153,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"QBia5YmyZG7r","outputId":"908d30db-4ca2-4465-8878-a5d7c043810a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/40, Training accuracy: 11.70%, Lr: 3.5000\n","Epoch 2/40, Training accuracy: 45.65%, Lr: 3.3250\n","Epoch 3/40, Training accuracy: 51.98%, Lr: 3.1587\n","Epoch 4/40, Training accuracy: 52.33%, Lr: 3.0008\n","Epoch 5/40, Training accuracy: 54.80%, Lr: 2.8508\n","Epoch 6/40, Training accuracy: 69.77%, Lr: 2.7082\n","Epoch 7/40, Training accuracy: 71.55%, Lr: 2.5728\n","Epoch 8/40, Training accuracy: 71.16%, Lr: 2.4442\n","Epoch 9/40, Training accuracy: 74.50%, Lr: 2.3220\n","Epoch 10/40, Training accuracy: 75.21%, Lr: 2.2059\n","Epoch 11/40, Training accuracy: 75.95%, Lr: 2.0956\n","Epoch 12/40, Training accuracy: 75.89%, Lr: 1.9908\n","Epoch 13/40, Training accuracy: 76.91%, Lr: 1.8913\n","Epoch 14/40, Training accuracy: 75.28%, Lr: 1.7967\n","Epoch 15/40, Training accuracy: 76.41%, Lr: 1.7069\n","Epoch 16/40, Training accuracy: 77.81%, Lr: 1.6215\n","Epoch 17/40, Training accuracy: 78.52%, Lr: 1.5404\n","Epoch 18/40, Training accuracy: 77.33%, Lr: 1.4634\n","Epoch 19/40, Training accuracy: 78.65%, Lr: 1.3903\n","Epoch 20/40, Training accuracy: 80.33%, Lr: 1.3207\n","Epoch 21/40, Training accuracy: 81.32%, Lr: 1.2547\n","Epoch 22/40, Training accuracy: 80.68%, Lr: 1.1920\n","Epoch 23/40, Training accuracy: 81.30%, Lr: 1.1324\n","Epoch 24/40, Training accuracy: 81.21%, Lr: 1.0757\n","Epoch 25/40, Training accuracy: 81.96%, Lr: 1.0220\n","Epoch 26/40, Training accuracy: 81.75%, Lr: 0.9709\n","Epoch 27/40, Training accuracy: 82.43%, Lr: 0.9223\n","Epoch 28/40, Training accuracy: 82.28%, Lr: 0.8762\n","Epoch 29/40, Training accuracy: 82.80%, Lr: 0.8324\n","Epoch 30/40, Training accuracy: 82.71%, Lr: 0.7908\n","Epoch 31/40, Training accuracy: 82.97%, Lr: 0.7512\n","Epoch 32/40, Training accuracy: 83.00%, Lr: 0.7137\n","Epoch 33/40, Training accuracy: 83.09%, Lr: 0.6780\n","Epoch 34/40, Training accuracy: 83.10%, Lr: 0.6441\n","Epoch 35/40, Training accuracy: 83.11%, Lr: 0.6119\n","Epoch 36/40, Training accuracy: 83.15%, Lr: 0.5813\n","Epoch 37/40, Training accuracy: 83.17%, Lr: 0.5522\n","Epoch 38/40, Training accuracy: 83.20%, Lr: 0.5246\n","Epoch 39/40, Training accuracy: 83.20%, Lr: 0.4984\n","Epoch 40/40, Training accuracy: 83.24%, Lr: 0.4735\n"]}],"source":["lr = 3.5\n","n_epochs = 40\n","n_features_fashion = X_train_fashion.shape[1]\n","\n","percept_fashion = Perceptron(n_features_fashion, n_class_fashion, lr, n_epochs)\n","\n","# - Refer to hints in the train method of the Perceptron class in \"models/perceptron.py\"\n","percept_fashion.train(X_train_fashion, y_train_fashion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126,"status":"ok","timestamp":1739909880280,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"ufy3-gKLZG7s","outputId":"03b3b3b3-27bd-446c-96c3-1f6152bca8c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["The training accuracy is given by: 83.282000\n"]}],"source":["pred_percept = percept_fashion.predict(X_train_fashion)\n","print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_fashion)))"]},{"cell_type":"markdown","metadata":{"id":"_MS3P9HhZG7s"},"source":["### Validate Perceptron on Fashion-MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82,"status":"ok","timestamp":1739909880363,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"3t8GaYdAZG7s","outputId":"51ab6c52-212c-4311-84b4-cda4b05f0311"},"outputs":[{"name":"stdout","output_type":"stream","text":["The validation accuracy is given by: 82.380000\n"]}],"source":["pred_percept = percept_fashion.predict(X_val_fashion)\n","print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_fashion)))"]},{"cell_type":"markdown","metadata":{"id":"txEvqRE1ZG7s"},"source":["### Test Perceptron on Fashion-MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119,"status":"ok","timestamp":1739909880486,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"tUJ30-Y_ZG7s","outputId":"dcd9c9da-3749-4d97-847c-710dfe0482de"},"outputs":[{"name":"stdout","output_type":"stream","text":["The testing accuracy is given by: 81.590000\n"]}],"source":["pred_percept = percept_fashion.predict(X_test_fashion)\n","print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_fashion)))"]},{"cell_type":"markdown","metadata":{"id":"_MQnHpTKZG7s"},"source":["## Train Perceptron on Rice"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86,"status":"ok","timestamp":1739909880784,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"OnYTf0izZG7s","outputId":"6f794a53-af8d-419b-aa4f-96cc36457821"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15, Training accuracy: 53.48%, Lr: 0.0500\n","Epoch 2/15, Training accuracy: 54.78%, Lr: 0.0475\n","Epoch 3/15, Training accuracy: 45.22%, Lr: 0.0451\n","Epoch 4/15, Training accuracy: 54.78%, Lr: 0.0429\n","Epoch 5/15, Training accuracy: 45.24%, Lr: 0.0407\n","Epoch 6/15, Training accuracy: 54.78%, Lr: 0.0387\n","Epoch 7/15, Training accuracy: 48.01%, Lr: 0.0368\n","Epoch 8/15, Training accuracy: 54.78%, Lr: 0.0349\n","Epoch 9/15, Training accuracy: 56.37%, Lr: 0.0332\n","Epoch 10/15, Training accuracy: 54.88%, Lr: 0.0315\n","Epoch 11/15, Training accuracy: 50.67%, Lr: 0.0299\n","Epoch 12/15, Training accuracy: 90.24%, Lr: 0.0284\n","Epoch 13/15, Training accuracy: 99.66%, Lr: 0.0270\n","Epoch 14/15, Training accuracy: 99.69%, Lr: 0.0257\n","Epoch 15/15, Training accuracy: 99.74%, Lr: 0.0244\n"]}],"source":["lr = 0.05\n","n_epochs = 15\n","n_features_RICE = X_train_RICE.shape[1]\n","\n","percept_RICE = Perceptron(n_features_RICE, n_class_RICE, lr, n_epochs)\n","percept_RICE.train(X_train_RICE, y_train_RICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1739909880789,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"yrSPlURFZG7s","outputId":"51462cb3-9cc4-4a27-b3f7-07fdc49d40b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["The training accuracy is given by: 99.761708\n"]}],"source":["pred_percept = percept_RICE.predict(X_train_RICE)\n","print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"HB9DyWF2ZG7s"},"source":["### Validate Perceptron on Rice"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1739909880833,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"bbBLnE0pZG7s","outputId":"1d6b68b8-d6f9-4e32-c8f6-0369d500f0ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["The validation accuracy is given by: 99.670058\n"]}],"source":["pred_percept = percept_RICE.predict(X_val_RICE)\n","print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"cEVADR4oZG7s"},"source":["### Test Perceptron on Rice"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1739909880879,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"HBCv7y6PZG7t","outputId":"1e20f91e-2f40-4d10-e9ec-b785880486ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["The testing accuracy is given by: 99.752543\n"]}],"source":["pred_percept = percept_RICE.predict(X_test_RICE)\n","print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"cr4DIp5OZG7t"},"source":["# Support Vector Machines (with SGD)"]},{"cell_type":"markdown","metadata":{"id":"Tz56hocDZG7t"},"source":["In the next phase of the project, I implemented a soft-margin Support Vector Machine (SVM). The objective was to maximize the margin between positive and negative training samples, while applying a penalty for margin violations using a hinge loss.\n","\n","To optimize the SVM loss, I used Stochastic Gradient Descent (SGD). This required computing the gradient of the loss with respect to the model’s weights and updating them iteratively.\n","\n","The SVM model had three key hyperparameters that I tuned:\n","* **Learning Rate**: Determines the step size during gradient updates. Similar to the Perceptron, I experimented with different values to observe the impact on convergence and model performance.\n","* **Epochs**: Specifies the number of times the entire dataset is passed through during training. I adjusted this based on how quickly the model was converging.\n","* **Regularization Constant**: Controls the strength of regularization, influencing how strictly the model maximizes the margin. I tested different values, starting with a default of 0.05, to see how it affected the trade-off between margin size and misclassification.\n","\n","The SVM implementation was developed in **models/svm.py**. Once the class was defined, I:\n","* Created an instance of the SVM classifier,\n","* Trained it on the dataset using the .train() method,\n","* Evaluated both training and testing accuracy using the .predict() method.\n","\n","This implementation allowed me to directly compare the performance of the SVM model with the previously built Perceptron, providing deeper insight into the behavior of linear classifiers under different optimization strategies."]},{"cell_type":"markdown","metadata":{"id":"ZgOVwULZZG7t"},"source":["## Train SVM on Fashion-MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56775,"status":"ok","timestamp":1739909937653,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"aScFCI73ZG7t","outputId":"0d561a6f-a87b-4e61-f36d-e08ea99a0bb5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/40, Training accuracy: 75.68%, Lr: 0.5000\n","Epoch 2/40, Training accuracy: 77.96%, Lr: 0.4750\n","Epoch 3/40, Training accuracy: 75.28%, Lr: 0.4512\n","Epoch 4/40, Training accuracy: 77.37%, Lr: 0.4287\n","Epoch 5/40, Training accuracy: 76.21%, Lr: 0.4073\n","Epoch 6/40, Training accuracy: 66.68%, Lr: 0.3869\n","Epoch 7/40, Training accuracy: 81.16%, Lr: 0.3675\n","Epoch 8/40, Training accuracy: 81.14%, Lr: 0.3492\n","Epoch 9/40, Training accuracy: 81.79%, Lr: 0.3317\n","Epoch 10/40, Training accuracy: 82.09%, Lr: 0.3151\n","Epoch 11/40, Training accuracy: 79.68%, Lr: 0.2994\n","Epoch 12/40, Training accuracy: 78.82%, Lr: 0.2844\n","Epoch 13/40, Training accuracy: 83.51%, Lr: 0.2702\n","Epoch 14/40, Training accuracy: 83.04%, Lr: 0.2567\n","Epoch 15/40, Training accuracy: 81.95%, Lr: 0.2438\n","Epoch 16/40, Training accuracy: 83.81%, Lr: 0.2316\n","Epoch 17/40, Training accuracy: 82.72%, Lr: 0.2201\n","Epoch 18/40, Training accuracy: 74.37%, Lr: 0.2091\n","Epoch 19/40, Training accuracy: 84.35%, Lr: 0.1986\n","Epoch 20/40, Training accuracy: 80.46%, Lr: 0.1887\n","Epoch 21/40, Training accuracy: 79.62%, Lr: 0.1792\n","Epoch 22/40, Training accuracy: 83.31%, Lr: 0.1703\n","Epoch 23/40, Training accuracy: 85.93%, Lr: 0.1618\n","Epoch 24/40, Training accuracy: 81.86%, Lr: 0.1537\n","Epoch 25/40, Training accuracy: 84.66%, Lr: 0.1460\n","Epoch 26/40, Training accuracy: 83.14%, Lr: 0.1387\n","Epoch 27/40, Training accuracy: 80.80%, Lr: 0.1318\n","Epoch 28/40, Training accuracy: 82.56%, Lr: 0.1252\n","Epoch 29/40, Training accuracy: 80.74%, Lr: 0.1189\n","Epoch 30/40, Training accuracy: 83.16%, Lr: 0.1130\n","Epoch 31/40, Training accuracy: 86.25%, Lr: 0.1073\n","Epoch 32/40, Training accuracy: 82.56%, Lr: 0.1020\n","Epoch 33/40, Training accuracy: 83.38%, Lr: 0.0969\n","Epoch 34/40, Training accuracy: 85.30%, Lr: 0.0920\n","Epoch 35/40, Training accuracy: 82.41%, Lr: 0.0874\n","Epoch 36/40, Training accuracy: 83.63%, Lr: 0.0830\n","Epoch 37/40, Training accuracy: 85.87%, Lr: 0.0789\n","Epoch 38/40, Training accuracy: 84.37%, Lr: 0.0749\n","Epoch 39/40, Training accuracy: 83.99%, Lr: 0.0712\n","Epoch 40/40, Training accuracy: 85.42%, Lr: 0.0676\n"]}],"source":["# Adjust the following four hyperparameters to achieve the best accuracy:\n","lr = 0.5\n","n_epochs = 40\n","reg_const = 0.05\n","batch_size = 256\n","\n","svm_fashion = SVM(n_features_fashion, n_class_fashion, lr, n_epochs, reg_const)\n","\n","# Refer to hints in the calculate_gradient and train methods of the SVM class in \"models/svm.py\"\n","svm_fashion.train(X_train_fashion, y_train_fashion, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":178,"status":"ok","timestamp":1739909937834,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"gycJEY_ZZG75","outputId":"fe64efa8-3fcc-4e9a-adae-85d51a9488b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["The training accuracy is given by: 85.424000\n"]}],"source":["pred_svm = svm_fashion.predict(X_train_fashion)\n","print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_fashion)))"]},{"cell_type":"markdown","metadata":{"id":"9XFVIKKrZG75"},"source":["### Validate SVM on Fashion-MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1739909937856,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"zZfoYiAtZG75","outputId":"c193fb00-8d8c-40b7-b21c-129d73cfae08"},"outputs":[{"name":"stdout","output_type":"stream","text":["The validation accuracy is given by: 81.690000\n"]}],"source":["pred_svm = svm_fashion.predict(X_val_fashion)\n","print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_fashion)))"]},{"cell_type":"markdown","metadata":{"id":"fWQgI1w1ZG75"},"source":["### Test SVM on Fashion-MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":92,"status":"ok","timestamp":1739909937956,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"FkfemSV8ZG75","outputId":"a29bb60b-8904-4b81-c97b-1882a696ee11"},"outputs":[{"name":"stdout","output_type":"stream","text":["The testing accuracy is given by: 81.350000\n"]}],"source":["pred_svm = svm_fashion.predict(X_test_fashion)\n","print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_fashion)))"]},{"cell_type":"markdown","metadata":{"id":"6NKuvOHUZG75"},"source":["## Train SVM on Rice"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101,"status":"ok","timestamp":1739909938446,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"v-yLMdh5ZG75","outputId":"6ae5c200-6d9e-4e95-d662-55c5f4145a7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5, Training accuracy: 99.97%, Lr: 0.0500\n","Epoch 2/5, Training accuracy: 99.97%, Lr: 0.0475\n","Epoch 3/5, Training accuracy: 99.95%, Lr: 0.0451\n","Epoch 4/5, Training accuracy: 99.96%, Lr: 0.0429\n","Epoch 5/5, Training accuracy: 99.97%, Lr: 0.0407\n"]}],"source":["# Adjust the following four hyperparameters to achieve the best accuracy:\n","lr = 0.05\n","n_epochs = 5\n","reg_const = 0.05\n","batch_size = 256\n","\n","svm_RICE = SVM(n_features_RICE, n_class_RICE, lr, n_epochs, reg_const)\n","svm_RICE.train(X_train_RICE, y_train_RICE, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1739909938468,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"eWDPIT0vZG76","outputId":"393ce38b-6f66-4158-d23b-94e01442f5c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["The training accuracy is given by: 99.972505\n"]}],"source":["pred_svm = svm_RICE.predict(X_train_RICE)\n","print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"wDUKfNXOZG76"},"source":["### Validate SVM on Rice"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72,"status":"ok","timestamp":1739909938552,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"Qd6VlJt-ZG76","outputId":"4ae243e8-6d29-4e89-f373-b8e25994cf61"},"outputs":[{"name":"stdout","output_type":"stream","text":["The validation accuracy is given by: 99.890019\n"]}],"source":["pred_svm = svm_RICE.predict(X_val_RICE)\n","print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"-N9mp3icZG76"},"source":["## Test SVM on Rice"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1739909938556,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"7CPWKXuiZG76","outputId":"3709d29c-cec9-4c76-97f8-068c0986c199"},"outputs":[{"name":"stdout","output_type":"stream","text":["The testing accuracy is given by: 99.972505\n"]}],"source":["pred_svm = svm_RICE.predict(X_test_RICE)\n","print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"nFp3mF0oZG76"},"source":["# Softmax Classifier (with SGD)"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"P8wZCdVsZG76"},"source":["As the final part of the project, I implemented a Softmax classifier. This model applies a linear transformation to the input data, followed by a softmax function that outputs a probability distribution over multiple classes. Each element of the output vector represents the model’s confidence in one of the possible classes, with all values summing to 1. The model was trained using a cross-entropy loss.\n","\n","To optimize the loss, I used Stochastic Gradient Descent (SGD). This required computing the gradient of the softmax cross-entropy loss with respect to the model weights and updating the weights accordingly.\n","\n","The softmax classifier included the following tunable hyperparameters:\n","* **Learning Rate** – Determines the step size of weight updates based on the computed gradients.\n","* **Number of Epochs** – Sets how many complete passes are made over the training dataset.\n","* **Regularization Constant** – Controls the strength of L2 regularization applied to the weights to prevent overfitting. I experimented with different values to find a good balance between model complexity and generalization.\n","\n","The implementation was done in **models/softmax.py**. After defining the class:\n","* I instantiated the Softmax classifier.\n","* Trained it on the dataset using the .train() method.\n","* Evaluated its performance by measuring training and testing accuracy with the .predict() method.\n","\n","This completed the set of linear models explored in this project, giving me a broader understanding of how different loss functions and optimization approaches influence classification performance."]},{"cell_type":"markdown","metadata":{"id":"p-_XqgCSZG76"},"source":["## Train Softmax on Fashion-MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9266,"status":"ok","timestamp":1740101084538,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"Ik2XafyHZG76","outputId":"f306ae0b-76de-4473-9905-d39943bca6fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1: training accuracy = 0.6318\n","Epoch 2: training accuracy = 0.6660\n","Epoch 3: training accuracy = 0.6281\n","Epoch 4: training accuracy = 0.7341\n","Epoch 5: training accuracy = 0.8246\n","Epoch 6: training accuracy = 0.8533\n","Epoch 7: training accuracy = 0.8536\n","Epoch 8: training accuracy = 0.8552\n","Epoch 9: training accuracy = 0.8553\n","Epoch 10: training accuracy = 0.8552\n","Epoch 11: training accuracy = 0.8552\n","Epoch 12: training accuracy = 0.8552\n","Epoch 13: training accuracy = 0.8552\n","Epoch 14: training accuracy = 0.8552\n","Epoch 15: training accuracy = 0.8552\n"]}],"source":["lr = 0.5\n","n_epochs = 15\n","reg_const = 0.5\n","\n","softmax_fashion = Softmax(n_class_fashion, lr, n_epochs, reg_const)\n","\n","# Refer to hints in the calculate_gradient and train methods of the Softmax class in \"models/softmax.py\"\n","softmax_fashion.train(X_train_fashion, y_train_fashion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1740101091981,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"9ZOHpS4RZG76","outputId":"764b096e-4636-413c-c0ce-b69b27a0f2c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["The training accuracy is given by: 85.518000\n"]}],"source":["pred_softmax = softmax_fashion.predict(X_train_fashion)\n","print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_fashion)))"]},{"cell_type":"markdown","metadata":{"id":"Q_Hbi33JZG76"},"source":["### Validate Softmax on Fashion-MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102,"status":"ok","timestamp":1740101093448,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"ifEHhDEmZG76","outputId":"0bc7e8ed-c38d-42b5-e3b5-470cf6a3603d"},"outputs":[{"name":"stdout","output_type":"stream","text":["The validation accuracy is given by: 83.950000\n"]}],"source":["pred_softmax = softmax_fashion.predict(X_val_fashion)\n","print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_fashion)))"]},{"cell_type":"markdown","metadata":{"id":"fsG7mOIgZG76"},"source":["### Testing Softmax on Fashion-MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104,"status":"ok","timestamp":1740101094667,"user":{"displayName":"Saniya Abushakimova","userId":"05417858338122514786"},"user_tz":360},"id":"AIl2criTZG76","outputId":"b83e582e-2d41-45c5-dcf4-50de633d75bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["The testing accuracy is given by: 83.160000\n"]}],"source":["pred_softmax = softmax_fashion.predict(X_test_fashion)\n","print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_fashion)))"]},{"cell_type":"markdown","metadata":{"id":"8LgHTCYyZG77"},"source":["## Train Softmax on Rice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOW4OcYRZG77","outputId":"7baf846d-dbc6-405c-cdf9-95efc691aaad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1: training accuracy = 0.9995\n","Epoch 2: training accuracy = 1.0000\n","Epoch 3: training accuracy = 1.0000\n","Epoch 4: training accuracy = 1.0000\n","Epoch 5: training accuracy = 1.0000\n"]}],"source":["lr = 0.4\n","n_epochs = 5\n","reg_const = 0.05\n","\n","softmax_RICE = Softmax(n_class_RICE, lr, n_epochs, reg_const)\n","softmax_RICE.train(X_train_RICE, y_train_RICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OvsDOgLLZG77","outputId":"27bc8111-aa31-4347-ef54-0a5422171412"},"outputs":[{"name":"stdout","output_type":"stream","text":["The training accuracy is given by: 100.000000\n"]}],"source":["pred_softmax = softmax_RICE.predict(X_train_RICE)\n","print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"fOyFpEDsZG77"},"source":["### Validate Softmax on Rice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDbIiN8bZG77","outputId":"1ae4d1a2-8b8f-4778-c60a-38969e60e13b"},"outputs":[{"name":"stdout","output_type":"stream","text":["The validation accuracy is given by: 99.945010\n"]}],"source":["pred_softmax = softmax_RICE.predict(X_val_RICE)\n","print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"UYXttcb7ZG77"},"source":["### Testing Softmax on Rice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oYqBWfc2ZG77","outputId":"97f6edfd-1929-4faa-ed29-71b24fc2650d"},"outputs":[{"name":"stdout","output_type":"stream","text":["The testing accuracy is given by: 100.000000\n"]}],"source":["pred_softmax = softmax_RICE.predict(X_test_RICE)\n","print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"khlSSX_PZG77"},"source":["# Logistic Classifier"]},{"cell_type":"markdown","metadata":{"id":"jhhRBZ--ZG77"},"source":["I also implemented a Logistic Regression classifier to explore binary classification using probabilistic decision boundaries. The model outputs values between 0 and 1, and a threshold is applied to determine the final class label.\n","\n","The implementation included the following key hyperparameters:\n","* **Learning Rate** – Controls the step size for updating weights based on the gradient.\n","* **Number of Epochs** – Determines how many times the full training dataset is passed through during training.\n","* **Threshold** – Sets the decision boundary for classification. Predictions above this threshold are assigned to one class, and those below to the other.\n","\n","The classifier was implemented in **models/logistic.py**. After defining the class, I:\n","* Created an instance of the logistic regression model.\n","* Trained it on the dataset using the .train() method.\n","* Evaluated its performance using the .predict() method to calculate both training and testing accuracy.\n","\n","This model provided a useful comparison point to the Perceptron, SVM, and Softmax classifiers, especially in terms of interpretability and performance on linearly separable data."]},{"cell_type":"markdown","metadata":{"id":"MaCAR-vJZG77"},"source":["### Training Logistic Classifer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nd6NSHPMZG77","outputId":"d3596c29-c4e1-4c01-d447-76921813b28e"},"outputs":[{"data":{"text/plain":["array([  1.95426249,   5.04570194, -17.28536458,  -4.18977314,\n","         4.77498026,  -8.99961048,   9.64371841,  -5.1267166 ,\n","        -4.11631723,  -0.33664439,  -0.08039806,  -2.80055505,\n","        11.42967033])"]},"execution_count":229,"metadata":{},"output_type":"execute_result"}],"source":["learning_rate = 0.5\n","n_epochs = 10\n","threshold = 0.5\n","\n","lr = Logistic(learning_rate, n_epochs, threshold)\n","\n","# Refer to hints in the sigmoid and train methods of the Logistic class in \"models/logistic.py\"\n","lr.train(X_train_RICE, y_train_RICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DF6E20FOZG77","outputId":"5f492c62-47eb-4b51-a009-91db79362199"},"outputs":[{"name":"stdout","output_type":"stream","text":["The training accuracy is given by: 100.000000\n"]}],"source":["pred_lr = lr.predict(X_train_RICE)\n","print('The training accuracy is given by: %f' % (get_acc(pred_lr, y_train_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"zjlECOPoZG77"},"source":["### Validate Logistic Classifer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLmv4_cXZG77","outputId":"28b96cee-7747-425c-c8d8-6fc1f11801de"},"outputs":[{"name":"stdout","output_type":"stream","text":["The validation accuracy is given by: 99.945010\n"]}],"source":["pred_lr = lr.predict(X_val_RICE)\n","print('The validation accuracy is given by: %f' % (get_acc(pred_lr, y_val_RICE)))"]},{"cell_type":"markdown","metadata":{"id":"8ZJl3YFBZG77"},"source":["### Test Logistic Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fd3-jpDaZG78","outputId":"951def29-40d7-4c4d-8913-7ea0de52168f"},"outputs":[{"name":"stdout","output_type":"stream","text":["The testing accuracy is given by: 100.000000\n"]}],"source":["pred_lr = lr.predict(X_test_RICE)\n","print('The testing accuracy is given by: %f' % (get_acc(pred_lr, y_test_RICE)))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"myenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"}},"nbformat":4,"nbformat_minor":0}